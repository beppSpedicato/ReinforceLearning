{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0c0b42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** PPO without UDR ***\n"
     ]
    }
   ],
   "source": [
    "from UDR.udr import train_test_ppo_with_udr\n",
    "from PPO.ppo_test import train_and_test_policy\n",
    "\n",
    "n_episodes = 20000\n",
    "mean_timestep = 300\n",
    "target_env = \"CustomHopper-target-v0\"\n",
    "source_env = \"CustomHopper-source-v0\"\n",
    "base_output_folder = \"./udr_output\"\n",
    "\n",
    "# optimized for PPO without UDR in source environment\n",
    "optimized_clip_range = 0.19877024509129543\n",
    "optimized_learning_rate = 0.0008\n",
    "optimized_gamma = 0.992\n",
    "\n",
    "print(\"*** PPO without UDR ***\")\n",
    "train_and_test_policy(\n",
    "    train_env=source_env,\n",
    "    test_env=target_env,\n",
    "    output_folder=f\"./{base_output_folder}/no-udr/\",\n",
    "    clip_range=optimized_clip_range,\n",
    "    learning_rate=optimized_learning_rate,\n",
    "    gamma=optimized_gamma,\n",
    "    episodes=n_episodes,\n",
    "    timesteps=mean_timestep,\n",
    "    print_std_deviation=True\n",
    ")\n",
    "\n",
    "deltas = [0.2, 0.5, 0.8]\n",
    "for delta in deltas:\n",
    "    print(f\"\\n*** PPO with UDR delta: {delta} ***\")\n",
    "    output_folder = f\"{base_output_folder}/{delta}\"\n",
    "\n",
    "    train_test_ppo_with_udr(\n",
    "\t\toutput_folder=output_folder,\n",
    "\t\ttrain_env=source_env,\n",
    "\t\ttest_env=target_env,\n",
    "\t\tepisodes=n_episodes,\n",
    "\t\tclip_range=optimized_clip_range,\n",
    "        learning_rate=optimized_learning_rate,\n",
    "        gamma=optimized_gamma,\n",
    "\t\ttimesteps=mean_timestep,\n",
    "\t\tdelta=delta,\n",
    "\t\tprint_std_deviation=True\n",
    "\t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9640c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def get_rewards (filename, window_size: int = 30):\n",
    "    with open(filename, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        data = [float(line.strip()) for line in lines]\n",
    "\n",
    "        means = []\n",
    "        positions = []\n",
    "        for i in range(0, len(data), window_size):\n",
    "            window = data[i:i+window_size]\n",
    "            mean_value = np.mean(window)\n",
    "            means.append(mean_value)\n",
    "            positions.append(i + window_size//2)\n",
    "        \n",
    "        return means, positions\n",
    "    \n",
    "path_test_resources = './trained-models/udr'\n",
    "\n",
    "for delta in deltas:\n",
    "    r, p = get_rewards(f\"{path_test_resources}/{delta}/test_rewards_CustomHopper-target-v0.txt\")\n",
    "    plt.plot(p, r, label=f'Source->target test rewards with UDR(delta={delta})', linewidth=2)\n",
    "\n",
    "\n",
    "s_t_test_rewards, st_positions = get_rewards(f'{path_test_resources}/no-udr/test_rewards_CustomHopper-target-v0.txt')\n",
    "plt.plot(st_positions, s_t_test_rewards, label=f'Source->target test rewards without UDR', linewidth=2)\n",
    "\n",
    "plt.ylabel(\"Rewards\")\n",
    "plt.xlabel(f\"Window ({10}) episodes\")\n",
    "plt.title(\"PPO test performance using different UDR parameters\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mldl_m4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
